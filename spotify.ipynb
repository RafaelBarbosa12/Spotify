{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esse notebook apresenta a previsão dos próximos hits do spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar os dados de treino e teste\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "\n",
    "# Ver as primeiras linhas dos datasets\n",
    "train_data_head = train_data.head()\n",
    "test_data_head = test_data.head()\n",
    "\n",
    "# Verificar informações gerais do dataset de treino\n",
    "train_info = train_data.info()\n",
    "\n",
    "train_data_head, test_data_head, train_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar a existência de valores nulos nos datasets\n",
    "missing_train = train_data.isnull().sum()\n",
    "missing_test = test_data.isnull().sum()\n",
    "\n",
    "# Análise estatística dos dados numéricos\n",
    "train_description = train_data.describe()\n",
    "\n",
    "missing_train, missing_test, train_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificação de variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento de valores nulos: preencher com string vazia para colunas categóricas\n",
    "test_data['artists'].fillna('', inplace=True)\n",
    "test_data['album_name'].fillna('', inplace=True)\n",
    "test_data['track_name'].fillna('', inplace=True)\n",
    "\n",
    "# Codificação de variáveis categóricas: vamos começar com 'explicit' e 'mode' (que são binárias)\n",
    "train_data['explicit'] = train_data['explicit'].astype('category')\n",
    "train_data['mode'] = train_data['mode'].astype('category')\n",
    "\n",
    "test_data['explicit'] = test_data['explicit'].astype('category')\n",
    "test_data['mode'] = test_data['mode'].astype('category')\n",
    "\n",
    "# Converter 'explicit' e 'mode' para numéricas\n",
    "train_data['explicit'] = train_data['explicit'].cat.codes\n",
    "train_data['mode'] = train_data['mode'].cat.codes\n",
    "\n",
    "test_data['explicit'] = test_data['explicit'].cat.codes\n",
    "test_data['mode'] = test_data['mode'].cat.codes\n",
    "\n",
    "# Verificar a codificação\n",
    "train_data[['explicit', 'mode']].head(), test_data[['explicit', 'mode']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Definir colunas numéricas para escalonamento\n",
    "numeric_cols = ['duration_ms', 'danceability', 'energy', 'loudness', 'speechiness', \n",
    "                'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'acousticness']\n",
    "\n",
    "# Aplicar MinMaxScaler para normalizar os dados numéricos entre 0 e 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data[numeric_cols] = scaler.fit_transform(train_data[numeric_cols])\n",
    "test_data[numeric_cols] = scaler.transform(test_data[numeric_cols])\n",
    "\n",
    "# Codificação de 'track_genre' usando o método 'category'\n",
    "train_data['track_genre'] = train_data['track_genre'].astype('category').cat.codes\n",
    "test_data['track_genre'] = test_data['track_genre'].astype('category').cat.codes\n",
    "\n",
    "# Verificar as mudanças nas colunas numéricas e de gênero\n",
    "train_data[numeric_cols + ['track_genre']].head(), test_data[numeric_cols + ['track_genre']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotar a distribuição da variável alvo\n",
    "sns.countplot(x='popularity_target', data=train_data)\n",
    "plt.title('Distribuição da Popularidade')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico acima mostra que a diferença entre as músicas populares e não populares é pequena, o que indica uma distribuição quase que igual entre essas targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a correlação\n",
    "corr_matrix = train_data[numeric_cols + ['popularity_target']].corr()\n",
    "\n",
    "# Exibir um heatmap das correlações\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlação entre Características Acústicas e Popularidade')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hipoteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipótese 1: Músicas com alta energia têm mais chances de serem populares\n",
    "\n",
    "Justificativa: Músicas com maior energia tendem a ser mais animadas, o que pode atrair mais ouvintes, especialmente em playlists populares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir um limiar para alta e baixa energia\n",
    "energia_limite = 0.5  # Definimos 0.5 como o ponto de corte\n",
    "\n",
    "# Contar o número de músicas populares em cada nível de energia\n",
    "energy_popularity_counts = train_data.groupby(\n",
    "    [train_data['energy'].apply(lambda x: 'Alta Energia' if x >= energia_limite else 'Baixa Energia'),\n",
    "     'popularity_target']\n",
    ").size().unstack()\n",
    "\n",
    "# Plotar o gráfico de barras\n",
    "energy_popularity_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['#1f77b4', '#ff7f0e'])\n",
    "plt.title('Quantidade de Músicas Populares por Nível de Energia')\n",
    "plt.xlabel('Nível de Energia')\n",
    "plt.ylabel('Quantidade de Músicas')\n",
    "plt.legend(['Não Popular', 'Popular'], title='Popularidade')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse gráfico mostra que dentre as músicas populares, a maioria delas são de baixa energia. Sendo assim, a hipótese é rejeitada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipótese 2: Músicas mais curtas têm maior chance de se tornarem virais\n",
    "\n",
    "Justificativa: Músicas com menor duração podem manter o interesse dos ouvintes em plataformas de streaming, onde a atenção é disputada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir um limiar para músicas curtas e longas (3 minutos = 180000 ms)\n",
    "duracao_limite = 180000  # 3 minutos\n",
    "\n",
    "# Contar o número de músicas populares em cada nível de duração\n",
    "duration_popularity_counts = train_data.groupby(\n",
    "    [train_data['duration_ms'].apply(lambda x: 'Curta' if x <= duracao_limite else 'Longa'), \n",
    "     'popularity_target']\n",
    ").size().unstack()\n",
    "\n",
    "# Plotar o gráfico de barras\n",
    "duration_popularity_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['#1f77b4', '#ff7f0e'])\n",
    "plt.title('Quantidade de Músicas Populares por Duração (Curta vs Longa)')\n",
    "plt.xlabel('Duração da Música')\n",
    "plt.ylabel('Quantidade de Músicas')\n",
    "plt.legend(['Não Popular', 'Popular'], title='Popularidade')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico mostra que dentre as músicas curtas, há mais músicas não populares do que populares. Sendo assim, a hipótese é rejeitada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipótese 3: Músicas mais dançantes (danceability) têm maior chance de se tornarem populares.\n",
    "\n",
    "A hipótese aqui é que músicas com características que as tornam boas para dançar (alta danceability) são mais atraentes para o público e, portanto, têm uma maior chance de viralizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar contagem de músicas populares por nível de dançabilidade\n",
    "danceability_popularity_counts = train_data.groupby(\n",
    "    [train_data['danceability'].apply(lambda x: 'Alta Danceability' if x >= 0.5 else 'Baixa Danceability'), \n",
    "     'popularity_target']\n",
    ").size().unstack()\n",
    "\n",
    "# Plotar o gráfico de barras empilhadas\n",
    "danceability_popularity_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['#1f77b4', '#ff7f0e'])\n",
    "plt.title('Quantidade de Músicas Populares por Nível de Dançabilidade')\n",
    "plt.xlabel('Nível de Dançabilidade')\n",
    "plt.ylabel('Quantidade de Músicas')\n",
    "plt.legend(['Não Popular', 'Popular'], title='Popularidade')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ver que a maioria das músicas populares são de baixa dançabilidade, mas ao mesmo tempo, a a maioria das não populares também são. Isso indica que há um equilibrio entre músicas de alta ou baixa dançabilidade em relação a popularidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar os dados entre features e target\n",
    "X = train_data.drop(columns=['popularity_target', 'track_unique_id', 'track_id', 'artists', 'album_name', 'track_name'])\n",
    "y = train_data['popularity_target']\n",
    "\n",
    "# Dividir entre treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção e Avaliação do Modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Instanciar o modelo\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Avaliar o modelo\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Acurácia: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões no conjunto de teste\n",
    "X_test = test_data.drop(columns=['track_unique_id', 'track_id', 'artists', 'album_name', 'track_name'])\n",
    "test_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Gerar arquivo CSV para submissão\n",
    "submission = test_data[['track_unique_id']].copy()\n",
    "submission['popularity_target'] = test_predictions\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Melhores parâmetros: {grid_search.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Fazer previsões no conjunto de validação usando o melhor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Acurácia com o modelo otimizado: {accuracy:.2f}')\n",
    "\n",
    "# Exibir outras métricas de avaliação\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_val, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
